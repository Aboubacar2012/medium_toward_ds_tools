{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f8a1e4",
   "metadata": {},
   "source": [
    "#### Boruta SHAP: A Tool for Feature Selection Every Data Scientist Should Know"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434f348",
   "metadata": {},
   "source": [
    "link : https://towardsdatascience.com/boruta-shap-an-amazing-tool-for-feature-selection-every-data-scientist-should-know-33a5f01285c0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b68f2",
   "metadata": {},
   "source": [
    "##### Shadow Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a922bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a511c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3cc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the data \n",
    "dataset=load_diabetes(as_frame=True)\n",
    "#Gets the independent variables \n",
    "X=dataset['data']\n",
    "# Gets the dependent variable (the target)\n",
    "y=dataset['target']\n",
    "# Splits the dataset\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf0e60",
   "metadata": {},
   "source": [
    "In order to use Boruta we need to define an estimator, which will be used to estimate the feature importances. In this case I chose the RandomForestRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b4b5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Defines the estimator used by the Boruta algorithm\n",
    "estimator=RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade553e",
   "metadata": {},
   "source": [
    "Now we can create the BorutaPy object and fit it to the data using the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8a93a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestRegressor(n_estimators=28,\n",
       "                                         random_state=RandomState(MT19937) at 0x7FA37E1EDB40),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x7FA37E1EDB40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "# create the BorutaPy object \n",
    "boruta=BorutaPy(estimator=estimator, n_estimators='auto',\n",
    "                max_iter=100)\n",
    "# Fits Boruta\n",
    "boruta.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bb77b",
   "metadata": {},
   "source": [
    "Finally we can discover which features are important, which are uninportant and which are uncertain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51b42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features confirmed as important :['bmi', 'bp', 's5']\n",
      "Unconfirmed features (tentative): ['s6']\n",
      "Features confirmed as unimportant: ['age', 'sex', 's1', 's2', 's3', 's4']\n"
     ]
    }
   ],
   "source": [
    "# Important features\n",
    "important =list(X.columns[boruta.support_])\n",
    "print(f\"Features confirmed as important :{important}\")\n",
    "\n",
    "# Tentative features \n",
    "tentative=list(X.columns[boruta.support_weak_])\n",
    "print(f\"Unconfirmed features (tentative): {tentative}\")\n",
    "\n",
    "#Unimportant features \n",
    "unimportant = list(X.columns[~(boruta.support_ | boruta.support_weak_)])\n",
    "print(f\"Features confirmed as unimportant: {unimportant}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50267a6a",
   "metadata": {},
   "source": [
    "##### Boruta SHAP Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329ab53",
   "metadata": {},
   "source": [
    "Boruta is a robust method for feature selection, but it strongly relies on the calculation of the feature importances, which might be biased or not good enough for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2ed59",
   "metadata": {},
   "source": [
    "This is where SHAP [3] joins the team. By using SHAP Values as the feature selection method in Boruta, we get the Boruta SHAP Feature Selection Algorithm. With this approach we can get the strong addictive feature explanations existent in SHAP method while having the robustness of Boruta algorithm to ensure only significant variables remain on the set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d79aab",
   "metadata": {},
   "source": [
    "First we need to create a BorutaShap object. The default value for importance_measure is “shap” since we want to use SHAP as the feature importance discriminator. We can change the classification parameter to True when the problem is a classification one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53a365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a BorutaShap Selector for regression \n",
    "selector=BorutaShap(importance_measure='shap', classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880b87e",
   "metadata": {},
   "source": [
    "Then we fit the BorutaShap selector in the data or a sample of the data. The n_trials parameter defines the number of iterations of the Boruta algorithm, while the sample boolean determines if the method will internally sample the data to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4212aa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e23b3868ee64f1d99a81f6a3e26b1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 attributes confirmed important: ['bp', 's2', 's5', 'bmi']\n",
      "6 attributes confirmed unimportant: ['age', 's6', 's4', 's1', 's3', 'sex']\n",
      "0 tentative attributes remains: []\n"
     ]
    }
   ],
   "source": [
    "# Fits the selector \n",
    "selector.fit(X=X_train, y=y_train, n_trials=100, \n",
    "            sample=False, verbose=True)\n",
    "# n_trials : number of iteratins for Boruta Algorithm\n",
    "# sample : samples the data so it goes faster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ad53e",
   "metadata": {},
   "source": [
    "Finally we can see which features will be removed and drop them from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1a36fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'sex' 's1' 's3' 's4' 's6']\n"
     ]
    }
   ],
   "source": [
    "# Display features to be removed \n",
    "features_to_remove=selector.features_to_remove\n",
    "print(features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9194cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove them \n",
    "X_train_boruta_shap=X_train.drop(columns=features_to_remove)\n",
    "X_test_boruta_shap=X_test.drop(columns=features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04c01675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s2</th>\n",
       "      <th>s5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.002228</td>\n",
       "      <td>0.070084</td>\n",
       "      <td>0.026714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.097264</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.023861</td>\n",
       "      <td>0.061686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.015350</td>\n",
       "      <td>-0.074528</td>\n",
       "      <td>-0.017284</td>\n",
       "      <td>-0.104365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-0.055785</td>\n",
       "      <td>0.025315</td>\n",
       "      <td>-0.023547</td>\n",
       "      <td>-0.005145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.030996</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-0.030996</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>0.023375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.063330</td>\n",
       "      <td>-0.057314</td>\n",
       "      <td>-0.048912</td>\n",
       "      <td>-0.059473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-0.025607</td>\n",
       "      <td>0.042530</td>\n",
       "      <td>-0.047660</td>\n",
       "      <td>0.001144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.058463</td>\n",
       "      <td>-0.043542</td>\n",
       "      <td>-0.072399</td>\n",
       "      <td>-0.051401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.084857</td>\n",
       "      <td>-0.016658</td>\n",
       "      <td>-0.041180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          bmi        bp        s2        s5\n",
       "309  0.001339 -0.002228  0.070084  0.026714\n",
       "403  0.097264 -0.005671 -0.023861  0.061686\n",
       "387  0.015350 -0.074528 -0.017284 -0.104365\n",
       "257 -0.055785  0.025315 -0.023547 -0.005145\n",
       "75  -0.030996 -0.026328 -0.001001  0.006209\n",
       "..        ...       ...       ...       ...\n",
       "307 -0.030996  0.004658  0.035638  0.023375\n",
       "34  -0.063330 -0.057314 -0.048912 -0.059473\n",
       "222 -0.025607  0.042530 -0.047660  0.001144\n",
       "411  0.058463 -0.043542 -0.072399 -0.051401\n",
       "389  0.001339 -0.084857 -0.016658 -0.041180\n",
       "\n",
       "[89 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_boruta_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2218c",
   "metadata": {},
   "source": [
    "##### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83269570",
   "metadata": {},
   "source": [
    "As important as feature selection is to our ML pipelines, we need to use the best algorithms to ensure the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba0093",
   "metadata": {},
   "source": [
    "A downside of this method is the evaluation time, which might be too long for many Boruta iterations, or when the SHAP is fitted to many observations. Beware of the time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab25006",
   "metadata": {},
   "source": [
    "With that in mind, Boruta SHAP is one of the best methods we can employ to select the most important features on our machine learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1e005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
