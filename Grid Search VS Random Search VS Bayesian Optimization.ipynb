{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search VS Random Search VS Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# load data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split data into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to fine-tune a random forest model with the grid search, random search, and Bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each method will be evaluated based on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The total number of trials executed\n",
    "- The number of trials needed to yield the optimal hyperparameters\n",
    "- The score of the model (f-1 score in this case)\n",
    "- The run time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier object and the search space are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# random forest classifier object\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define sample space\n",
    "param_grid = {\n",
    "    'n_estimators': [100,150,200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [5, 6, 7]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altogether, there are 810 unique hyperparameter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s obtain the optimal hyperparameters using the grid search method and time the process. Of course, this means that we will test all 810 hyperparameter sets and pick out the one that yields the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 810 candidates, totalling 4050 fits\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create grid search object\n",
    "gs = GridSearchCV(estimator=rfc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='f1_micro',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "\n",
    "# perform hyperparameter tuning (while timing the process)\n",
    "time_start = time.time()\n",
    "gs.fit(X_train, y_train)\n",
    "time_grid = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_grid = [810, gs.best_index_+1, gs.best_score_, time_grid]\n",
    "columns = ['Number of iterations', 'Iteration Number of Optimal Hyperparamters', 'Score', 'Time Elapsed (s)']\n",
    "results_grid = pd.DataFrame([values_grid], columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the random search to identify the optimal hyperparameters and time the process. The search is limited to 100 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# create a random search object\n",
    "rs = RandomizedSearchCV(estimator=rfc,\n",
    "                  param_distributions=param_grid,\n",
    "                  scoring='f1_micro',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2,\n",
    "                  n_iter=100)\n",
    "\n",
    "# perform hyperparamter tuning (while timing the process)\n",
    "time_start = time.time()\n",
    "rs.fit(X_train, y_train)\n",
    "time_random = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_grid = [[100, rs.best_index_+1, rs.best_score_, time_random]]\n",
    "results_random = pd.DataFrame(values_grid, columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform hyperparameter tuning with the Bayesian optimization and time the process. In Python, this can be accomplished with the Optuna module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its syntax differs from that of Sklearn, but it performs the same operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of consistency, we will use 100 trials in this procedure as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-03 18:06:22,939]\u001b[0m A new study created in memory with name: no-name-89ee3c92-a1fb-4e7c-8f0e-2115369deb7c\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:26,131]\u001b[0m Trial 0 finished with value: 0.9131488365689109 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 0 with value: 0.9131488365689109.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:27,320]\u001b[0m Trial 1 finished with value: 0.9116673550874295 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 0 with value: 0.9131488365689109.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:28,376]\u001b[0m Trial 2 finished with value: 0.9131653586672174 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:29,306]\u001b[0m Trial 3 finished with value: 0.9079498829684702 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:30,240]\u001b[0m Trial 4 finished with value: 0.896800220294644 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:30,990]\u001b[0m Trial 5 finished with value: 0.893085501858736 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:31,928]\u001b[0m Trial 6 finished with value: 0.8982817017761257 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:32,725]\u001b[0m Trial 7 finished with value: 0.9116673550874295 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:33,734]\u001b[0m Trial 8 finished with value: 0.907941621919317 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:34,227]\u001b[0m Trial 9 finished with value: 0.9123943274129147 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 2 with value: 0.9131653586672174.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:34,812]\u001b[0m Trial 10 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9287401900041307.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:35,370]\u001b[0m Trial 11 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9287401900041307.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:35,916]\u001b[0m Trial 12 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9287401900041307.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:36,446]\u001b[0m Trial 13 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:36,971]\u001b[0m Trial 14 finished with value: 0.9228004956629492 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:37,536]\u001b[0m Trial 15 finished with value: 0.9228004956629492 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:38,363]\u001b[0m Trial 16 finished with value: 0.9294864381109734 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:39,188]\u001b[0m Trial 17 finished with value: 0.9205727660746247 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:40,001]\u001b[0m Trial 18 finished with value: 0.9146413327825966 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:41,080]\u001b[0m Trial 19 finished with value: 0.9176070494286108 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:41,867]\u001b[0m Trial 20 finished with value: 0.9146275643673413 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:42,460]\u001b[0m Trial 21 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:43,013]\u001b[0m Trial 22 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:43,598]\u001b[0m Trial 23 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:44,138]\u001b[0m Trial 24 finished with value: 0.9228004956629492 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:44,669]\u001b[0m Trial 25 finished with value: 0.9131626049841663 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:45,392]\u001b[0m Trial 26 finished with value: 0.9280022029464409 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:45,869]\u001b[0m Trial 27 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:46,410]\u001b[0m Trial 28 finished with value: 0.9176042957455597 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:47,042]\u001b[0m Trial 29 finished with value: 0.9280022029464409 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:47,888]\u001b[0m Trial 30 finished with value: 0.9294864381109734 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:48,530]\u001b[0m Trial 31 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:49,083]\u001b[0m Trial 32 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:49,653]\u001b[0m Trial 33 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:50,242]\u001b[0m Trial 34 finished with value: 0.9220652622883106 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:50,775]\u001b[0m Trial 35 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:51,343]\u001b[0m Trial 36 finished with value: 0.9228004956629492 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:52,091]\u001b[0m Trial 37 finished with value: 0.9168580476387168 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:52,719]\u001b[0m Trial 38 finished with value: 0.9280022029464409 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:53,258]\u001b[0m Trial 39 finished with value: 0.9131626049841663 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:53,985]\u001b[0m Trial 40 finished with value: 0.9094148423516455 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:54,526]\u001b[0m Trial 41 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:55,081]\u001b[0m Trial 42 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:55,686]\u001b[0m Trial 43 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:56,481]\u001b[0m Trial 44 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:57,024]\u001b[0m Trial 45 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 13 with value: 0.9309651659094038.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:57,665]\u001b[0m Trial 46 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 46 with value: 0.9331956491807792.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:58,262]\u001b[0m Trial 47 finished with value: 0.9250254715682225 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 46 with value: 0.9331956491807792.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:59,318]\u001b[0m Trial 48 finished with value: 0.9265289825141126 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 46 with value: 0.9331956491807792.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:06:59,929]\u001b[0m Trial 49 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:00,551]\u001b[0m Trial 50 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:01,142]\u001b[0m Trial 51 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:01,771]\u001b[0m Trial 52 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:02,393]\u001b[0m Trial 53 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:03,005]\u001b[0m Trial 54 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:03,547]\u001b[0m Trial 55 finished with value: 0.9064601404378356 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:04,141]\u001b[0m Trial 56 finished with value: 0.9280022029464409 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:04,862]\u001b[0m Trial 57 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:05,722]\u001b[0m Trial 58 finished with value: 0.9228115103951534 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:06,449]\u001b[0m Trial 59 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:07,027]\u001b[0m Trial 60 finished with value: 0.9220652622883106 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:07,662]\u001b[0m Trial 61 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:08,283]\u001b[0m Trial 62 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:08,894]\u001b[0m Trial 63 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:09,564]\u001b[0m Trial 64 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:10,209]\u001b[0m Trial 65 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:10,885]\u001b[0m Trial 66 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:11,528]\u001b[0m Trial 67 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:12,068]\u001b[0m Trial 68 finished with value: 0.9309596585433016 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:12,702]\u001b[0m Trial 69 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:13,868]\u001b[0m Trial 70 finished with value: 0.9272669695718022 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:14,498]\u001b[0m Trial 71 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:15,239]\u001b[0m Trial 72 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:16,087]\u001b[0m Trial 73 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:16,711]\u001b[0m Trial 74 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:17,304]\u001b[0m Trial 75 finished with value: 0.9250309789343246 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:17,924]\u001b[0m Trial 76 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:18,520]\u001b[0m Trial 77 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:19,105]\u001b[0m Trial 78 finished with value: 0.9280022029464409 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:20,056]\u001b[0m Trial 79 finished with value: 0.9317114140162467 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:20,621]\u001b[0m Trial 80 finished with value: 0.922048740190004 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:21,249]\u001b[0m Trial 81 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:21,891]\u001b[0m Trial 82 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:22,562]\u001b[0m Trial 83 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:23,224]\u001b[0m Trial 84 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:23,852]\u001b[0m Trial 85 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:24,512]\u001b[0m Trial 86 finished with value: 0.9235439900867408 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:25,054]\u001b[0m Trial 87 finished with value: 0.9309596585433016 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:25,660]\u001b[0m Trial 88 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:26,253]\u001b[0m Trial 89 finished with value: 0.9280022029464409 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:26,867]\u001b[0m Trial 90 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:27,487]\u001b[0m Trial 91 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:28,102]\u001b[0m Trial 92 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:28,934]\u001b[0m Trial 93 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:29,536]\u001b[0m Trial 94 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:30,125]\u001b[0m Trial 95 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:30,717]\u001b[0m Trial 96 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:31,315]\u001b[0m Trial 97 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:31,847]\u001b[0m Trial 98 finished with value: 0.9064601404378356 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n",
      "\u001b[32m[I 2022-05-03 18:07:32,502]\u001b[0m Trial 99 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.9346853917114141.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"return the f1-score\"\"\"\n",
    "\n",
    "    # search space\n",
    "    n_estimators =  trial.suggest_int('n_estimators', low=100, high=200, step=50)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', low=2, high=4, step=1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', low=1, high=5, step=1)\n",
    "    max_depth = trial.suggest_int('max_depth', low=5, high=7, step=1)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt','log2'])\n",
    "\n",
    "    # random forest classifier object\n",
    "    rfc = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                                  criterion=criterion,\n",
    "                                                  min_samples_split=min_samples_split,\n",
    "                                                  min_samples_leaf=min_samples_leaf,\n",
    "                                                  max_depth=max_depth,\n",
    "                                                  max_features=max_features,\n",
    "                                                  random_state=42)\n",
    "    score =  cross_val_score(estimator=rfc, \n",
    "                             X=X_train, \n",
    "                             y=y_train, \n",
    "                             scoring='f1_micro',\n",
    "                             cv=5,\n",
    "                             n_jobs=-1).mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# create a study (aim to maximize score)\n",
    "study = optuna.create_study(sampler=TPESampler(), direction='maximize')\n",
    "\n",
    "# perform hyperparamter tuning (while timing the process)\n",
    "time_start = time.time()\n",
    "study.optimize(objective, n_trials=100)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [100, study.best_trial.number, study.best_trial.value, time_bayesian]\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have executed hyperparameter tuning with all three approaches, let’s see how the results of each method compare to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we will store the results of all 3 hyperparameter tuning procedures in a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of iterations</th>\n",
       "      <th>Iteration Number of Optimal Hyperparamters</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time Elapsed (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Grid Search</td>\n",
       "      <td>810</td>\n",
       "      <td>680</td>\n",
       "      <td>0.935426</td>\n",
       "      <td>488.608124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Search</td>\n",
       "      <td>100</td>\n",
       "      <td>43</td>\n",
       "      <td>0.933196</td>\n",
       "      <td>63.926313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bayesian Optimization</td>\n",
       "      <td>100</td>\n",
       "      <td>49</td>\n",
       "      <td>0.934685</td>\n",
       "      <td>69.563363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Number of iterations  \\\n",
       "Grid Search                             810   \n",
       "Random Search                           100   \n",
       "Bayesian Optimization                   100   \n",
       "\n",
       "                       Iteration Number of Optimal Hyperparamters     Score  \\\n",
       "Grid Search                                                   680  0.935426   \n",
       "Random Search                                                  43  0.933196   \n",
       "Bayesian Optimization                                          49  0.934685   \n",
       "\n",
       "                       Time Elapsed (s)  \n",
       "Grid Search                  488.608124  \n",
       "Random Search                 63.926313  \n",
       "Bayesian Optimization         69.563363  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store all results in a single data frame\n",
    "df = results_grid.append(results_random).append(results_bayesian)\n",
    "df.index = ['Grid Search', 'Random Search', 'Bayesian Optimization']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search registered the highest score (joint with the Bayesian optimization method). However, the method required carrying out 810 trials and only managed to obtain the optimal hyperparameters at the 680th iteration. Also, its run time far exceeded that of the random search and the Bayesian optimization methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random search method required only 100 trials and needed only 36 iterations to find the best hyperparameter set. It also took the least amount of time to execute. However, the random search method registered the lowest score out of the 3 methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian optimization also performed 100 trials but was able to achieve the highest score after only 49 iterations, far less than the grid search’s 680 iterations. Although it executed the same number of trials as the random search, it has a longer run time since it is an informed search method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you hate diplomatic answers and just want my personal opinion, I would say that I usually favor the Bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the run time needed for fine-tuning models with larger training data sets and search spaces, I usually shun the grid search. The random search requires fewer iterations and is the fastest of all 3 methods, but its level of success depends on the hyperparameter sets that are selected at random. In some cases, it will select the optimal hyperparameters; in other cases, it will omit the optimal hyperparameters completely. Due to this inconsistency, I do not like relying on randomness for bigger machine learning tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer the Bayesian optimization approach for its ability to consistently attain the optimal hyperparameters with fewer iterations. Its individual iterations may take more time than those of the uninformed search methods, but that is rarely a deal-breaker for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
