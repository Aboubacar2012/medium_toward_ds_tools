{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 382154 entries, 0 to 382153\n",
      "Data columns (total 12 columns):\n",
      "id                      382154 non-null int64\n",
      "Gender                  382154 non-null object\n",
      "Age                     382154 non-null int64\n",
      "Driving_License         382154 non-null int64\n",
      "Region_Code             382154 non-null float64\n",
      "Previously_Insured      382154 non-null int64\n",
      "Vehicle_Age             382154 non-null object\n",
      "Vehicle_Damage          382154 non-null object\n",
      "Annual_Premium          382154 non-null float64\n",
      "Policy_Sales_Channel    382154 non-null float64\n",
      "Vintage                 382154 non-null int64\n",
      "Response                382154 non-null int64\n",
      "dtypes: float64(3), int64(6), object(3)\n",
      "memory usage: 35.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "df_raw = pd.read_csv('aug_train.csv')\n",
    "\n",
    "# show columns in dataset\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target label is “Response”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to any model building, we need to preprocess the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing values\n",
    "df = df_raw.dropna()\n",
    "\n",
    "# remove id column\n",
    "df = df.drop('id', axis=1)\n",
    "\n",
    "# identify categorical variables\n",
    "cat_var = [column for column in df if df[column].dtype=='object']\n",
    "\n",
    "# one hot encode categorical variables\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        dummies = pd.get_dummies(df[col])\n",
    "        df = pd.concat([df, dummies], axis=1)     \n",
    "df = df.drop(cat_var, axis=1)\n",
    "\n",
    "# create input and output data\n",
    "target = 'Response'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick count shows us the number of records in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 319553, 1: 62601})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# count the frequency of each class\n",
    "count = Counter(y)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of the size of the majority class to that of the minority class is about 5:1, a strong indicator of data imbalance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s build a random forest model to predict customer interest in vehicle insurance without SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# normalize the data \n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "# generate predictions with the random forest classifier\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll evaluate this model with the f-1 score metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score of model without SMOTE: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# compute the f-1 score\n",
    "f1 = np.round(f1_score(y_test, y_pred),2)\n",
    "print('F-1 score of model without SMOTE: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will repeat the same procedure, but after adding artificial data. We can do this in Python with the imblearn module’s SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# create artificial data with SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how SMOTE is only applied on the training set. As mentioned previously, it is very important not to generate artificial data for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 239759, 0: 239759})\n"
     ]
    }
   ],
   "source": [
    "# count number of records in each class\n",
    "count = Counter(y_train_smote)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data imbalance in the training data has now been addressed. So, let’s build a random forest classifier with this data and see how it performs on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of model with SMOTE: 0.52\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "mms = MinMaxScaler()\n",
    "X_train_smote = mms.fit_transform(X_train_smote)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "# create random forest model and generate predictions\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = rfc.predict(X_test)\n",
    "\n",
    "# compute the f-1 score\n",
    "f1_smote = round(f1_score(y_test, y_pred_smote),2)\n",
    "print('F1-score of model with SMOTE: {}'.format(f1_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model registers an f-1 score of 0.52, proving to be a better predictor of customer interest in vehicle insurance compared to the model trained without artificial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
